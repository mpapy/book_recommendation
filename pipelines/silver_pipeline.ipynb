{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8964dd7-e2ca-404a-a3b6-3800119e95b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9899488b-b634-4702-b937-356b704679a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import dlt\n",
    "\n",
    "# Environment configuration\n",
    "env = spark.conf.get(\"pipeline.env\") or \"dev\"  # Default to dev if not set\n",
    "catalog = \"book_rec_catalog\"\n",
    "\n",
    "# Schema names\n",
    "bronze_schema = f\"{env}_bronze\"\n",
    "silver_schema = f\"{env}_silver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70271c7d-b348-457e-92b0-447946b184b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Silver layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "946c8cb2-582f-4d2c-8743-3348422d832a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simple Silver layer - just clean the data\n",
    "@dlt.table(name=f\"{silver_schema}.books_silver\", comment=\"Silver table for cleaned Books data\")\n",
    "@dlt.expect(\"valid_isbn\", \"ISBN IS NOT NULL AND ISBN != ''\")\n",
    "@dlt.expect(\"valid_book_title\", \"`Book-Title` IS NOT NULL AND `Book-Title` != ''\")\n",
    "@dlt.expect(\"valid_book_author\", \"`Book-Author` IS NOT NULL AND `Book-Author` != ''\")\n",
    "def books_silver():\n",
    "    return (spark.table(f\"{bronze_schema}.books_bronze\")\n",
    "            .withColumn(\"Year-Of-Publication\", \n",
    "                       when(col(\"Year-Of-Publication\").cast(\"int\").isNotNull(), \n",
    "                            col(\"Year-Of-Publication\").cast(\"int\"))\n",
    "                       .otherwise(None))\n",
    "            .withColumn(\"Publisher\", \n",
    "                       when(col(\"Publisher\").isNotNull() & (col(\"Publisher\") != \"\"), \n",
    "                            trim(col(\"Publisher\")))\n",
    "                       .otherwise(\"Unknown\"))\n",
    "            .withColumn(\"Book-Title\", trim(col(\"Book-Title\")))\n",
    "            .withColumn(\"Book-Author\", trim(col(\"Book-Author\")))\n",
    "            .withColumn(\"ISBN\", trim(col(\"ISBN\")))\n",
    "            .withColumn(\"cleaned_ts\", current_timestamp())\n",
    "    )\n",
    "\n",
    "@dlt.table(name=f\"{silver_schema}.ratings_silver\", comment=\"Silver table for cleaned Ratings data\")\n",
    "@dlt.expect(\"valid_user_id\", \"`User-ID` IS NOT NULL\")\n",
    "@dlt.expect(\"valid_isbn\", \"ISBN IS NOT NULL AND ISBN != ''\")\n",
    "@dlt.expect(\"valid_book_rating\", \"`Book-Rating` IS NOT NULL AND `Book-Rating` >= 0 AND `Book-Rating` <= 10\")\n",
    "def ratings_silver():\n",
    "    return (spark.table(f\"{bronze_schema}.ratings_bronze\")\n",
    "            .withColumn(\"Book-Rating\", \n",
    "                       when(col(\"Book-Rating\").cast(\"int\").isNotNull(), \n",
    "                            col(\"Book-Rating\").cast(\"int\"))\n",
    "                       .otherwise(None))\n",
    "            .withColumn(\"ISBN\", trim(col(\"ISBN\")))\n",
    "            .withColumn(\"cleaned_ts\", current_timestamp())\n",
    "    )\n",
    "\n",
    "@dlt.table(name=f\"{silver_schema}.users_silver\", comment=\"Silver table for cleaned Users data\")\n",
    "@dlt.expect(\"valid_user_id\", \"`User-ID` IS NOT NULL\")\n",
    "def users_silver():\n",
    "    return (spark.table(f\"{bronze_schema}.users_bronze\")\n",
    "            .withColumn(\"Age\", \n",
    "                       when(col(\"Age\").cast(\"int\").isNotNull(), \n",
    "                            col(\"Age\").cast(\"int\"))\n",
    "                       .otherwise(None))\n",
    "            .withColumn(\"Location\", \n",
    "                       when(col(\"Location\").isNotNull() & (col(\"Location\") != \"\"), \n",
    "                            trim(col(\"Location\")))\n",
    "                       .otherwise(\"Unknown\"))\n",
    "            # Split Location into city, region, state with proper handling\n",
    "            .withColumn(\"location_cleaned\", \n",
    "                       when(col(\"Location\") != \"Unknown\",\n",
    "                            # Replace / with , but preserve n/a\n",
    "                            regexp_replace(col(\"Location\"), r'(?<!n)/(?!a)', \", \"))\n",
    "                       .otherwise(\"Unknown\"))\n",
    "            .withColumn(\"location_parts\", \n",
    "                       when(col(\"location_cleaned\") != \"Unknown\",\n",
    "                            split(col(\"location_cleaned\"), \",\"))\n",
    "                       .otherwise(array(lit(\"Unknown\"))))\n",
    "            .withColumn(\"city\", \n",
    "                       when((size(col(\"location_parts\")) >= 1) & \n",
    "                            (trim(element_at(col(\"location_parts\"), 1)) != \"\"), \n",
    "                            initcap(trim(element_at(col(\"location_parts\"), 1))))\n",
    "                       .otherwise(\"Unknown\"))\n",
    "            .withColumn(\"region\", \n",
    "                       when((size(col(\"location_parts\")) >= 2) & \n",
    "                            (trim(element_at(col(\"location_parts\"), 2)) != \"\"), \n",
    "                            initcap(trim(element_at(col(\"location_parts\"), 2))))\n",
    "                       .otherwise(\"Unknown\"))\n",
    "            .withColumn(\"state\", \n",
    "                       when((size(col(\"location_parts\")) >= 3) & \n",
    "                            (trim(element_at(col(\"location_parts\"), 3)) != \"\"), \n",
    "                            initcap(trim(element_at(col(\"location_parts\"), 3))))\n",
    "                       .otherwise(\"Unknown\"))\n",
    "            .drop(\"location_parts\", \"location_cleaned\")  # Remove temporary columns\n",
    "            .withColumn(\"cleaned_ts\", current_timestamp())\n",
    "    )\n",
    "\n",
    "# Quarantine tables for problematic data\n",
    "@dlt.table(name=f\"{silver_schema}.books_quarantine\", comment=\"Quarantine table for problematic Books data\")\n",
    "def books_quarantine():\n",
    "    return (spark.table(f\"{bronze_schema}.books_bronze\")\n",
    "            .filter((col(\"ISBN\").isNull()) | (col(\"ISBN\") == \"\") |\n",
    "                   (col(\"Book-Title\").isNull()) | (col(\"Book-Title\") == \"\") |\n",
    "                   (col(\"Book-Author\").isNull()) | (col(\"Book-Author\") == \"\"))\n",
    "            .withColumn(\"quarantine_reason\", \n",
    "                       when((col(\"ISBN\").isNull()) | (col(\"ISBN\") == \"\"), \"Missing ISBN\")\n",
    "                       .when((col(\"Book-Title\").isNull()) | (col(\"Book-Title\") == \"\"), \"Missing Title\")\n",
    "                       .when((col(\"Book-Author\").isNull()) | (col(\"Book-Author\") == \"\"), \"Missing Author\")\n",
    "                       .otherwise(\"Multiple Issues\"))\n",
    "            .withColumn(\"quarantine_ts\", current_timestamp())\n",
    "    )\n",
    "\n",
    "@dlt.table(name=f\"{silver_schema}.ratings_quarantine\", comment=\"Quarantine table for problematic Ratings data\")\n",
    "def ratings_quarantine():\n",
    "    return (spark.table(f\"{bronze_schema}.ratings_bronze\")\n",
    "            .filter((col(\"User-ID\").isNull()) |\n",
    "                   (col(\"ISBN\").isNull()) | (col(\"ISBN\") == \"\") |\n",
    "                   (col(\"Book-Rating\").isNull()) |\n",
    "                   (col(\"Book-Rating\") < 0) | (col(\"Book-Rating\") > 10))\n",
    "            .withColumn(\"quarantine_reason\", \n",
    "                       when(col(\"User-ID\").isNull(), \"Missing User ID\")\n",
    "                       .when((col(\"ISBN\").isNull()) | (col(\"ISBN\") == \"\"), \"Missing ISBN\")\n",
    "                       .when(col(\"Book-Rating\").isNull(), \"Missing Rating\")\n",
    "                       .when((col(\"Book-Rating\") < 0) | (col(\"Book-Rating\") > 10), \"Invalid Rating\")\n",
    "                       .otherwise(\"Multiple Issues\"))\n",
    "            .withColumn(\"quarantine_ts\", current_timestamp())\n",
    "    )\n",
    "\n",
    "@dlt.table(name=f\"{silver_schema}.users_quarantine\", comment=\"Quarantine table for problematic Users data\")\n",
    "def users_quarantine():\n",
    "    return (spark.table(f\"{bronze_schema}.users_bronze\")\n",
    "            .filter(col(\"User-ID\").isNull())\n",
    "            .withColumn(\"quarantine_reason\", lit(\"Missing User ID\"))\n",
    "            .withColumn(\"quarantine_ts\", current_timestamp())\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
